{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4c7518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "def get_youtube_transcript(video_id):\n",
    "        try:\n",
    "                transcripts = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "                first_transcript = transcripts.find_transcript([t.language_code for t in transcripts])\n",
    "                transcript = first_transcript.fetch().to_raw_data()\n",
    "                return transcript\n",
    "        \n",
    "        except Exception as e:\n",
    "                print(f\"⚠️ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08e8f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yt_dlp import YoutubeDL\n",
    "\n",
    "class YouTubeInfoExtractor:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.info = self._fetch_info()\n",
    "\n",
    "    def _fetch_info(self):\n",
    "        ydl_opts = {'skip_download': True}\n",
    "        with YoutubeDL(ydl_opts) as ydl:\n",
    "            return ydl.extract_info(self.url, download=False)\n",
    "\n",
    "    def get_title(self):\n",
    "        return self.info.get('title')\n",
    "\n",
    "    def get_chapters(self):\n",
    "        return self.info.get('chapters')\n",
    "\n",
    "    def get_upload_date(self):\n",
    "        return self.info.get('upload_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83cf2736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_transcript_by_chapters(transcript, chapters):\n",
    "\n",
    "    chapters_transcript = []\n",
    "\n",
    "    for chapter in chapters:\n",
    "        chapter_transcript = [\n",
    "            t[\"text\"]\n",
    "            for t in transcript\n",
    "            if chapter[\"start_time\"] <= t[\"start\"] < chapter[\"end_time\"]\n",
    "            ]\n",
    "        \n",
    "        chapters_transcript.append({\n",
    "            chapter['title']: ' '.join(chapter_transcript)\n",
    "        })\n",
    "\n",
    "    return chapters_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "531d42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load variables from .env into environment\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model = os.getenv(\"OPENAI_MODEL_NAME\")\n",
    "\n",
    "\n",
    "# Create OpenAI client\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def summarize(dictionary):\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes text and makes the output into CSV format without any extra text.\"},\n",
    "            \n",
    "            {\"role\": \"user\", \"content\": \n",
    "                f\"\"\"You'll create a csv row with 4 cells using dictionary name {dictionary} you'll receive.\n",
    "                \n",
    "                Dictionary has:\n",
    "                    - Key = Title (DO NOT summarize or change it. Use it as-is.)\n",
    "                    - Value = Content about the key (you need to summarize and divide into fields).\n",
    "\n",
    "                Expected Output:\n",
    "                    1. have 4 cells:\n",
    "                        - DICTIONARY KEY\n",
    "                        - Descriptions about the key.\n",
    "                        - Features related to the key.\n",
    "                        - Specific usage examples.\n",
    "\n",
    "                    2. No extra text or explanation. Output only has CSV format.\n",
    "                    3. Separate each cell with | instead of comma.\n",
    "\n",
    "                Example output:\n",
    "                엔비디아, 모든 소리 생성 가능한 AI 공개|음악부터 효과음까지 모든 소리를 생성|사운드와 스피치와 뮤직이 통합된 모델|효과음을 음악으로 변환, 음악에서 보컬 분리, 텍스트로 소리 생성 및 변환\n",
    "                \"\"\"},\n",
    "            ],\n",
    "                temperature=0.5,\n",
    "                max_tokens=300,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63b74c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_csv_text(date, transcript, url, chapters, title):\n",
    "    csv_text = []\n",
    "    \n",
    "    for chapter, dictionary in zip(chapters, transcript):\n",
    "        ai_summary = summarize(dictionary)\n",
    "        row = ai_summary.split(\"|\")\n",
    "\n",
    "        # Add date as the first cell\n",
    "        row.insert(0, date)\n",
    "\n",
    "        # Create the timestamped link for the current chapter\n",
    "        link = f'=HYPERLINK(\"{url}&t={int(chapter[\"start_time\"])}\", \"{title}\")'\n",
    "        row.append(link)\n",
    "\n",
    "        # Add the full row to the CSV list\n",
    "        csv_text.append(row)\n",
    "\n",
    "    return csv_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c8e4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_base_url(url):\n",
    "    # This regex grabs the main video URL without the timestamp\n",
    "    match = re.match(r\"(https:\\/\\/www\\.youtube\\.com\\/watch\\?v=[^&]+)\", url)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    # fallback if regex doesn't match\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc5b3fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def save_to_csv(csv_text, new_link, filename=\"AI_News.csv\"):\n",
    "    # check if file existed\n",
    "    file_exists = os.path.exists(filename)\n",
    "\n",
    "    seen = set()\n",
    "\n",
    "    # check duplication\n",
    "    if file_exists:\n",
    "        with open(filename, \"r\", encoding=\"utf-8-sig\") as file:\n",
    "            reader = csv.reader(file)\n",
    "            # Skip the header and get the next row. if it doesn't exist, return None.\n",
    "            next(reader, None)\n",
    "\n",
    "            for row in reader:\n",
    "                if row:\n",
    "                    seen_link = get_base_url(row[-1])\n",
    "                    seen.add(seen_link)\n",
    "\n",
    "    if new_link in seen:\n",
    "        print(f\"Duplicate link found ({new_link}), skipping...\")\n",
    "        return\n",
    "\n",
    "    else:\n",
    "        # 'a' mode for append, 'w' mode for write if new file\n",
    "        with open(filename, \"a\", newline=\"\", encoding=\"utf-8-sig\") as file:\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "            # If the file does not exist yet, write header first\n",
    "            if not file_exists:\n",
    "                writer.writerow([\"Upload Date\", \"Title\", \"Description\", \"Features\", \"Usage Examples\", \"Link\"])\n",
    "            writer.writerows(csv_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62e1093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=g1XIwhDgs1o\n",
      "[youtube] g1XIwhDgs1o: Downloading webpage\n",
      "[youtube] g1XIwhDgs1o: Downloading tv client config\n",
      "[youtube] g1XIwhDgs1o: Downloading player 9a279502-main\n",
      "[youtube] g1XIwhDgs1o: Downloading tv player API JSON\n",
      "[youtube] g1XIwhDgs1o: Downloading ios player API JSON\n",
      "[youtube] g1XIwhDgs1o: Downloading m3u8 information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: ffmpeg not found. The downloaded format may not be the best available. Installing ffmpeg is strongly recommended: https://github.com/yt-dlp/yt-dlp#dependencies\n"
     ]
    }
   ],
   "source": [
    "video_id = \"g1XIwhDgs1o\"\n",
    "video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "\n",
    "full_transcript = get_youtube_transcript(video_id)\n",
    "\n",
    "info = YouTubeInfoExtractor(video_url)\n",
    "title, chapters, date = info.get_title(), info.get_chapters(), info.get_upload_date()\n",
    "\n",
    "chapters_transcript = group_transcript_by_chapters(transcript=full_transcript, chapters=chapters)[:2]\n",
    "\n",
    "csv_text = finalize_csv_text(date=date, transcript=chapters_transcript, url=video_url, chapters=chapters, title=title)\n",
    "\n",
    "save_to_csv(csv_text=csv_text, new_link=video_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
