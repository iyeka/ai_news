{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c7518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "def get_youtube_transcript(video_id):\n",
    "        try:\n",
    "                transcripts = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "                first_transcript = transcripts.find_transcript([t.language_code for t in transcripts])\n",
    "                transcript = first_transcript.fetch().to_raw_data()\n",
    "                return transcript\n",
    "        \n",
    "        except Exception as e:\n",
    "                print(f\"⚠️ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08e8f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yt_dlp import YoutubeDL\n",
    "\n",
    "class YouTubeInfoExtractor:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.info = self._fetch_info()\n",
    "\n",
    "    def _fetch_info(self):\n",
    "        ydl_opts = {'skip_download': True}\n",
    "        with YoutubeDL(ydl_opts) as ydl:\n",
    "            return ydl.extract_info(self.url, download=False)\n",
    "\n",
    "    def get_title(self):\n",
    "        return self.info.get('title')\n",
    "\n",
    "    def get_chapters(self):\n",
    "        return self.info.get('chapters')\n",
    "\n",
    "    def get_upload_date(self):\n",
    "        return self.info.get('upload_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83cf2736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_transcript_by_chapters(transcript, chapters):\n",
    "\n",
    "    chapters_transcript = []\n",
    "\n",
    "    for chapter in chapters:\n",
    "        chapter_transcript = [\n",
    "            t[\"text\"]\n",
    "            for t in transcript\n",
    "            if chapter[\"start_time\"] <= t[\"start\"] < chapter[\"end_time\"]\n",
    "            ]\n",
    "        \n",
    "        chapters_transcript.append({\n",
    "            chapter['title']: ' '.join(chapter_transcript)\n",
    "        })\n",
    "\n",
    "    return chapters_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531d42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load variables from .env into environment\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model = os.getenv(\"OPENAI_MODEL_NAME\")\n",
    "\n",
    "# Create OpenAI client\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def summarize(dictionary):\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes text and makes the output into CSV format without any extra text.\"},\n",
    "            \n",
    "            {\"role\": \"user\", \"content\": \n",
    "                f\"\"\"You'll create a csv row with 4 cells using dictionary name {dictionary} you'll receive.\n",
    "                \n",
    "                Dictionary has:\n",
    "                    - Key = Title (DO NOT summarize or change it. Use it as-is.)\n",
    "                    - Value = Content about the key (you need to summarize and divide into fields).\n",
    "\n",
    "                Expected Output:\n",
    "                    1. have 4 cells:\n",
    "                        - DICTIONARY KEY\n",
    "                        - Descriptions about the key.\n",
    "                        - Features related to the key.\n",
    "                        - Specific usage examples.\n",
    "\n",
    "                    2. No extra text or explanation. Output only has CSV format.\n",
    "                    3. Separate each cell with | instead of comma.\n",
    "\n",
    "                Example output:\n",
    "                엔비디아, 모든 소리 생성 가능한 AI 공개|음악부터 효과음까지 모든 소리를 생성|사운드와 스피치와 뮤직이 통합된 모델|효과음을 음악으로 변환, 음악에서 보컬 분리, 텍스트로 소리 생성 및 변환\n",
    "                \"\"\"},\n",
    "            ],\n",
    "                temperature=0.5,\n",
    "                max_tokens=300,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b74c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_csv_text(date, transcript, url, chapters, title):\n",
    "    csv_text = []\n",
    "    \n",
    "    for chapter, dictionary in zip(chapters, transcript):\n",
    "        ai_summary = summarize(dictionary)\n",
    "        row = ai_summary.split(\"|\")\n",
    "\n",
    "        # Add date as the first cell\n",
    "        row.insert(0, date)\n",
    "\n",
    "        # Create the timestamped link for the current chapter\n",
    "        link = f'=HYPERLINK(\"{url}&t={int(chapter[\"start_time\"])}\", \"{title}\")'\n",
    "        row.append(link)\n",
    "\n",
    "        # Add the full row to the CSV list\n",
    "        csv_text.append(row)\n",
    "\n",
    "    return csv_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c8e4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_base_url(url):\n",
    "    # This regex grabs the main video URL without the timestamp\n",
    "    match = re.match(r\"(https:\\/\\/www\\.youtube\\.com\\/watch\\?v=[^&]+)\", url)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    # fallback if regex doesn't match\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc5b3fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# --------- Setup Google Sheets API ---------\n",
    "creds = service_account.Credentials.from_service_account_file(\n",
    "'credentials.json',\n",
    "scopes=['https://www.googleapis.com/auth/spreadsheets']\n",
    ")\n",
    "\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "sheet = service.spreadsheets()\n",
    "\n",
    "# --------- Define your Spreadsheet ---------\n",
    "SPREADSHEET_ID = '1qr_CluX6H4sUEfHwbntpRhj4kj2ldTaCENN00IT-8rg'\n",
    "SHEET_NAME = 'AI_News'\n",
    "\n",
    "def save_to_google_sheet(csv_text, new_link):\n",
    "    seen = set()\n",
    "\n",
    "    # 1. Read all existing rows to check duplication\n",
    "    result = sheet.values().get(spreadsheetId=SPREADSHEET_ID,\n",
    "                            range=f\"{SHEET_NAME}!F2:F\").execute()\n",
    "    existing_rows = result.get('values', [])\n",
    "\n",
    "    for row in existing_rows:\n",
    "        if row:\n",
    "            seen_link = get_base_url(row[-1])  # last column = link\n",
    "            seen.add(seen_link)\n",
    "\n",
    "    if new_link in seen:\n",
    "        print(f\"Duplicate link found ({new_link}), skipping...\")\n",
    "        return\n",
    "    # 2. Append the new data\n",
    "    else:\n",
    "        body = {\n",
    "        'values': csv_text\n",
    "    }\n",
    "        response = sheet.values().append(\n",
    "            spreadsheetId=SPREADSHEET_ID,\n",
    "            range=f\"{SHEET_NAME}!A2:Z\",\n",
    "            valueInputOption=\"USER_ENTERED\",\n",
    "            insertDataOption=\"INSERT_ROWS\",\n",
    "            body=body\n",
    "        ).execute()\n",
    "\n",
    "        print(f\"✅ New data appended successfully: {response.get('updates').get('updatedRange')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e1093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=veAe2OtUgkY\n",
      "[youtube] veAe2OtUgkY: Downloading webpage\n",
      "[youtube] veAe2OtUgkY: Downloading tv client config\n",
      "[youtube] veAe2OtUgkY: Downloading player 9a279502-main\n",
      "[youtube] veAe2OtUgkY: Downloading tv player API JSON\n",
      "[youtube] veAe2OtUgkY: Downloading ios player API JSON\n",
      "[youtube] veAe2OtUgkY: Downloading m3u8 information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: ffmpeg not found. The downloaded format may not be the best available. Installing ffmpeg is strongly recommended: https://github.com/yt-dlp/yt-dlp#dependencies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ New data appended successfully: AI_News!A116:F164\n"
     ]
    }
   ],
   "source": [
    "def main(video_id):\n",
    "    video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "\n",
    "    full_transcript = get_youtube_transcript(video_id)\n",
    "\n",
    "    info = YouTubeInfoExtractor(video_url)\n",
    "    title, chapters, date = info.get_title(), info.get_chapters(), info.get_upload_date()\n",
    "\n",
    "    chapters_transcript = group_transcript_by_chapters(transcript=full_transcript, chapters=chapters)\n",
    "\n",
    "    csv_text = finalize_csv_text(date=date, transcript=chapters_transcript, url=video_url, chapters=chapters, title=title)\n",
    "\n",
    "    save_to_google_sheet(csv_text=csv_text, new_link=video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e4f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = \"CBT4xfblyXQ\"\n",
    "main(video_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
